# HYPER STREAM

### 프로젝트 배경 및 문제 정의: 데이터 폭증의 시대

라이브 스트리밍 시장은 단순한 영상 전달을 넘어, 사용자가 직접 시청 관점을 선택하는 방향으로 진화하고 있다. 특히 축구 중계와 같은 대규모 스포츠 이벤트에서 시청자는 경기 전체 뷰뿐만 아니라, 특정 선수(Player Cam), 전술 뷰 등 다수의 시점을 동시에 소비하기를 원한다.

예를 들어 한 팀 11명의 선수를 개별적으로 추적하는 시나리오를 가정할 경우, 서버는 최소 11개의 UHD(4K) 고해상도 스트림을 실시간으로 수신하고 처리해야 한다. 이는 단순한 영상 서비스의 확장이 아니라, 초당 수십 GB에 달하는 픽셀 데이터를 지연 없이 처리해야 하는 문제에 해당한다. 기존의 단일 스트림 중심 아키텍처로는 이러한 대규모 병렬 데이터 처리를 구조적으로 감당할 수 없다.

그리고 이러한 멀티뷰 경험을 클라이언트 단에서 직접 처리하는 것은 현실적으로 불가능하다. 모바일 기기나 저사양 PC 환경에서는 다수의 고해상도 스트림을 동시에 수신·디코딩하는 것 자체가 하드웨어 한계를 초과하며, 네트워크 대역폭 측면에서도 수많은 스트림을 병렬로 전달하는 방식은 비효율적이다. 결과적으로 **표준 플레이어 환경을 유지하면서 멀티뷰를 제공하기 위해서는 서버사이드에서의 실시간 합성이 필수적**이다.

---

### 기존 구현의 한계: FFmpeg 파이프라인의 직렬화 병목

현재 업계 표준인 FFmpeg `filter_complex` 기반 멀티뷰 구현은 순차적 오버레이(Sequential Overlay) 방식을 따른다. 이 방식은 구조적으로 HPC 환경에 적합하지 않은 근본적인 한계를 가진다.

첫째, 스트림 개수 N에 대해 N번의 오버레이 필터가 직렬로 연결되며, 각 단계마다 불필요한 Global Memory Read/Write가 반복된다. 이는 VRAM 메모리 대역폭을 급격히 소모시키는 주요 원인이 된다.

둘째, 각 필터 단계마다 개별 CUDA 커널이 실행·종료되면서, 실제 픽셀 연산 비용보다 커널 런치 및 동기화 오버헤드가 지배적인 비용으로 작용한다.

셋째, 스트림 수 증가에 따라 파이프라인 깊이(Depth)가 선형적으로 증가하며, UHD 스트림 환경에서는 레이턴시가 기하급수적으로 증가하는 구조적 한계를 보인다.

본 팀은 선행 연구로 4채널 UHD 멀티뷰 프로토타입을 구현하였으나, 스트림 확장 과정에서 프레임 드랍과 급격한 처리 지연을 관측하였다. 이는 단순한 파라미터 튜닝이나 하드웨어 증설로 해결할 수 있는 문제가 아니라, **FFmpeg 필터 체인의 직렬화 구조 자체에서 기인한 아키텍처 레벨의 병목**임이라고 판단하였다.

---

### 제안하는 접근 방식: O(1) 합성 복잡도의 병렬 멀티뷰 엔진

본 프로젝트는 FFmpeg의 직렬화된 필터 체인을 제거하고, **Custom CUDA Kernel 기반의 병렬 멀티뷰 합성 엔진**을 제안한다.

제안하는 구조에서는 다수의 입력 스트림을 개별적으로 오버레이하지 않고, GPU 메모리에 상주하는 모든 디코딩 프레임을 단일 커널에서 병렬 스레드로 접근하여 합성한다. 이를 통해 스트림 개수와 무관하게 합성 단계의 커널 실행 오버헤드를 1회로 고정(O(1))하는 것을 목표로 한다.

또한 디코딩된 프레임 포인터를 직접 참조하는 Zero-Copy 구조를 통해 불필요한 메모리 복사를 제거하고, 사용자 레이아웃 변경 시 파이프라인 재구성 없이 커널 파라미터 업데이트만으로 반응하는 **Near-Zero Latency** 화면 전환을 구현하고자 한다.

본 해커톤에서는 이 접근 방식을 통해 11개 이상의 UHD 스트림 환경에서도 일정한 처리 특성을 유지할 수 있음을 검증하고, 기존 FFmpeg 기반 방식 대비 압도적인 처리량과 반응성을 실험적으로 입증하는 것을 목표로 한다.

---

### 구현 목표: 사용자 선택 기반 동적 멀티뷰 합성 시나리오

본 프로젝트는 추상적인 멀티뷰 개념 검증을 넘어, 실제 서비스 적용을 가정한 구체적인 합성 시나리오를 구현 대상으로 한다.

구체적으로, **11개 이상의 UHD 입력 스트림 중에서** 하나의 메인 화면(Main View)과 사용자가 선택한 3개의 개별 화면(Sub View)을 조합하여, **총 4화면으로 구성된 커스터마이징 멀티뷰를 실시간으로 합성**하는 것을 목표로 한다.

사용자는 재생 중 언제든지 서브 화면에 노출될 스트림 조합을 변경할 수 있으며, 이 요청은 FFmpeg 필터 그래프의 재구성이나 파이프라인 재시작 없이, **CUDA 커널 파라미터 업데이트만으로 즉시 반영**된다. 이를 통해 프레임 드랍이나 추가 레이턴시 없이, 실시간 관점 전환이 가능한 서버사이드 멀티뷰 합성의 실효성을 검증한다.

본 시나리오는 클라이언트 단에서 다수의 스트림을 동시에 디코딩할 수 없는 모바일 및 저사양 환경에서도, 단일 표준 스트림만으로 초개인화된 멀티뷰 경험을 제공할 수 있음을 실증하는 것을 목표로 한다.
